Automatically generated by Mendeley 1.9.1
Any changes to this file will be lost if it is regenerated by Mendeley.

@misc{PAL1962,
abstract = {PAL, short for Phase Alternating Line, is a colour encoding system for analogue television used in broadcast television systems in most countries broadcasting at 576i. Other common analogue television systems are NTSC and SECAM. This page primarily discusses the PAL colour encoding system. The articles on broadcast television systems and analogue television further describe frame rates, image resolution and audio modulation. For discussion of the 625-line / 50 field (25 frame) per second television standard, see 576i.},
author = {Bruch, Walter},
title = {{Phase Alternating Line (PAL)}},
url = {https://en.wikipedia.org/wiki/PAL},
year = {1962}
}
@article{Zhou2008,
abstract = {Although Augmented Reality technology was first developed over forty years ago, there has been little survey work giving an overview of recent research in the field. This paper reviews the ten-year development of the work presented at the ISMAR conference and its predecessors with a particular focus on tracking, interaction and display research. It provides a roadmap for future augmented reality research which will be of great value to this relatively young field, and also for helping researchers decide which topics should be explored when they are beginning their own studies in the area.},
author = {Zhou, Feng and Duh, Henry Been-lirn and Billinghurst, Mark},
doi = {10.1109/ISMAR.2008.4637362},
editor = {Livingston, Mark A and Bimber, Oliver and Saito, Hideo},
file = {:Users/eduardolundgren/Google Drive/Faculdade/msc-ufpe-thesis/referencias/Zhou.Trends in Augmented.Reality.Tracking.pdf:pdf},
isbn = {9781424428403},
journal = {2008 7th IEEEACM International Symposium on Mixed and Augmented Reality},
number = {4},
pages = {193--202},
publisher = {Ieee},
series = {ISMAR '08},
title = {{Trends in augmented reality tracking, interaction and display: A review of ten years of ISMAR}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4637362},
volume = {2},
year = {2008}
}
@article{Rosten2010,
abstract = {The repeatability and efficiency of a corner detector determines how likely it is to be useful in a real-world application. The repeatability is importand because the same scene viewed from different positions should yield features which correspond to the same real-world 3D locations Schmid et al 2000. The efficiency is important because this determines whether the detector combined with further processing can operate at frame rate. Three advances are described in this paper. First, we present a new heuristic for feature detection, and using machine learning we derive a feature detector from this which can fully process live PAL video using less than 5\% of the available processing time. By comparison, most other detectors cannot even operate at frame rate (Harris detector 115\%, SIFT 195\%). Second, we generalize the detector, allowing it to be optimized for repeatability, with little loss of efficiency. Third, we carry out a rigorous comparison of corner detectors based on the above repeatability criterion applied to 3D scenes. We show that despite being principally constructed for speed, on these stringent tests, our heuristic detector significantly outperforms existing feature detectors. Finally, the comparison demonstrates that using machine learning produces significant improvements in repeatability, yielding a detector that is both very fast and very high quality.},
author = {Rosten, Edward and Porter, Reid and Drummond, Tom},
file = {:Users/eduardolundgren/Library/Application Support/Mendeley Desktop/Downloaded/Rosten, Drummond - Unknown - Machine learning for high-speed corner detection.pdf:pdf},
institution = {Department of Engineering, Cambridge University, Cambridge, UK. er258@cam.ac.uk},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
number = {1},
pages = {1--14},
publisher = {IEEE},
title = {{Machine learning for high-speed corner detection}},
url = {http://arxiv.org/abs/0810.2434},
volume = {32},
year = {2010}
}
@misc{Vorbis2012,
author = {Foundation, Xiph.Org},
title = {{Vorbis specification}},
url = {http://xiph.org/vorbis/doc/Vorbis\_I\_spec.html},
year = {2012}
}
@inproceedings{Wendt2008,
abstract = {This study proposes augmented reality from mobile devices based on SIFT (Scale Invariant Feature Transform) features for markerless outdoor augmented reality application. The proposed application is navigation help in a city. These SIFT features are projected on a digital model of the building facades of the square to obtain 3D co-ordinates for each feature point. The algorithms implemented calculate the camera pose for frame of a video from 3D-2D point correspondences between features extracted in the current video frame and points in the reference dataset. The algorithms were successfully tested on video films of city squares. Although they do not operate in real-time, they are capable of a correct pose estimation and projection of artificial data into the scene. In case of a loss of track, the algorithms recover automatically. The study shows the potential of SIFT features for purely image based markerless outdoor augmented reality applications. This study takes place in the MoSAIC project.},
author = {Wendt, Frank Lorenz and Bres, Stephane and Tellez, Bruno and Laurini, Robert},
booktitle = {IMAGE AND SIGNAL PROCESSING},
isbn = {9783540699040},
issn = {03029743},
keywords = {content based image retrieval; image matching; aug},
organization = {Inst Uni Technol Cherbourg Manche; Univ Caen Basse Normandie; ENSICAEN; Ctr Natl Recherche Sci; Conseil Reg Basse Normandie; Conseil General Manche; Commun Urbaine Cherbourg; Pole Transactions Electron Securisees},
pages = {439--446},
publisher = {SPRINGER-VERLAG BERLIN},
series = {LECTURE NOTES IN COMPUTER SCIENCE},
title = {{Markerless outdoor localisation based on SIFT descriptors for mobile applications}},
volume = {5099},
year = {2008}
}
@misc{MDN2013,
abstract = {All parts of MDN (docs, demos, and the site itself) are created by an open community of developers.},
author = {Mozilla, Inc.},
title = {{Mozilla Developer Network}},
url = {https://developer.mozilla.org/en-US/},
year = {2013}
}
@article{International2009,
abstract = {This Ecma Standard is based on several originating technologies, the most well known being JavaScript (Netscape) and JScript (Microsoft). The language was invented by Brendan Eich at Netscape and first appeared in that companys Navigator 2.0 browser. It has appeared in all subsequent browsers from Netscape and in all browsers from Microsoft starting with Internet Explorer 3.0. The development of this Standard started in November 1996. The first edition of this Ecma Standard was adopted by the Ecma General Assembly of June 1997. That Ecma Standard was submitted to ISO/IEC JTC 1 for adoption under the fast-track procedure, and approved as international standard ISO/IEC 16262, in April 1998. The Ecma General Assembly of June 1998 approved the second edition of ECMA-262 to keep it fully aligned with ISO/IEC 16262. Changes between the first and the second edition are editorial in nature. The third edition of the Standard introduced powerful regular expressions, better string handling, new control statements, try/catch exception handling, tighter definition of errors, formatting for numeric output and minor changes in anticipation of forthcoming internationalisation facilities and future language growth. The third edition of the ECMAScript standard was adopted by the Ecma General Assembly of December 1999 and published as ISO/IEC 16262:2002 in June 2002. Since publication of the third edition, ECMAScript has achieved massive adoption in conjunction with the World Wide Web where it has become the programming language that is supported by essentially all web browsers. Significant work was done to develop a fourth edition of ECMAScript. Although that work was not completed and not published1 as the fourth edition of ECMAScript, it informs continuing evolution of the language. The present fifth edition of ECMAScript (published as ECMA-262 5th edition) codifies de facto interpretations of the language specification that have become common among browser implementations and adds support for new features that have emerged since the publication of the third edition. Such features include accessor properties, reflective creation and inspection of objects, program control of property attributes, additional array manipulation functions, support for the JSON object encoding format, and a strict mode that provides enhanced error checking and program security. ECMAScript is a vibrant language and the evolution of the language is not complete. Significant technical enhancement will continue with future editions of this specification.},
author = {International, Ecma},
institution = {ECMA},
issn = {09544879},
journal = {JavaScript Specification},
number = {December},
pages = {1--252},
publisher = {ECMA International, http://www.ecma-international.org},
title = {{ECMA-262 ECMAScript Language Specification}},
url = {http://www.ecma-international.org/publications/standards/Ecma-262.htm},
volume = {16},
year = {2009}
}
@article{Azuma1997,
abstract = {This paper surveys the field of Augmented Reality, in which 3-D virtual objects are integrated into a 3-D real environment in real time. It describes the medical, manufacturing, visualization, path planning, entertainment and military applications that have been explored. This paper describes the characteristics of Augmented Reality systems, including a detailed discussion of the tradeoffs between optical and video blending approaches. Registration and sensing errors are two of the biggest problems in building effective Augmented Reality systems, so this paper summarizes current efforts to overcome these problems. Future directions and areas requiring further research are discussed. This survey provides a starting point for anyone interested in researching or using Augmented Reality.},
author = {Azuma, Ronald T},
doi = {10.1.1.30.4999},
file = {:Users/eduardolundgren/Library/Application Support/Mendeley Desktop/Downloaded/Azuma - 1997 - A Survey of Augmented Reality.pdf:pdf},
issn = {10547460},
journal = {Media},
number = {August},
pages = {355--385},
publisher = {Citeseer},
title = {{A Survey of Augmented Reality}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.35.5387\&amp;rep=rep1\&amp;type=pdf},
volume = {6},
year = {1997}
}
@inproceedings{Grosskurth2005,
author = {Grosskurth, Alan and Godfrey, M.W. Michael W},
booktitle = {Software Maintenance, 2005. ICSM'05. Proceedings of the 21st IEEE International Conference on},
doi = {10.1109/ICSM.2005.13},
file = {:Users/eduardolundgren/Google Drive/Faculdade/msc-ufpe-thesis/referencias/Alan.Grosskurth.Web.pdf:pdf},
isbn = {0-7695-2368-4},
keywords = {and has evolved significantly,component reuse,perhaps the most widely,reference architecture,software architecture,software evolution,the web browser is,used soft-,ware application in history,web browser},
organization = {IEEE},
pages = {661--664},
publisher = {IEEE},
title = {{A reference architecture for web browsers}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1510168},
year = {2005}
}
@article{Jia2012,
abstract = {Sparse representation has been applied to visual tracking by finding the best candidate with minimal reconstruction error using target templates. However most sparse representation based trackers only consider the holistic representation and do not make full use of the sparse coefficients to discriminate between the target and the background, and hence may fail with more possibility when there is similar object or occlusion in the scene. In this paper we develop a simple yet robust tracking method based on the structural local sparse appearance model. This representation exploits both partial information and spatial information of the target based on a novel alignment-pooling method. The similarity obtained by pooling across the local patches helps not only locate the target more accurately but also handle occlusion. In addition, we employ a template update strategy which combines incremental subspace learning and sparse representation. This strategy adapts the template to the appearance change of the target with less possibility of drifting and reduces the influence of the occluded target template as well. Both qualitative and quantitative evaluations on challenging benchmark image sequences demonstrate that the proposed tracking algorithm performs favorably against several state-of-the-art methods.},
author = {Jia, Xu and Lu, Huchuan},
doi = {10.1109/CVPR.2012.6247880},
isbn = {9781467312288},
issn = {10636919},
journal = {IEEE Conference on Computer Vision and Pattern Recognition (2008)},
pages = {1822--1829},
publisher = {Ieee},
title = {{Visual Tracking via Adaptive Structural Local Sparse Appearance Model}},
url = {http://faculty.ucmerced.edu/mhyang/papers/cvpr12c.pdf},
year = {2012}
}
@misc{Traffic2013,
abstract = {he following overview of page requests per client (\~{}browser) application is based on the user agent information that accompanies most server requests. Please note that agent information does not follow strict guidelines and some programs may provide wrong information on purpose. This report ignores all requests where agent information is missing, or contains any of the following: bot, crawl(er) or spider.},
author = {Wikimedia},
title = {{Wikimedia Traffic Analysis Report - Browsers}},
url = {http://stats.wikimedia.org/archive/squid\_reports/2012-07/SquidReportClients.htm},
year = {2013}
}
@article{CSS2013,
abstract = {This page contains descriptions of all specifications that the CSS WG is working on.},
author = {W3C},
title = {{Descriptions of all CSS specifications}},
url = {http://www.w3.org/Style/CSS/specs.en.html},
year = {2013}
}
@misc{TypedArrayPerformance2013,
abstract = {Typed Arrays Performance comparison},
author = {{A Lundgren Melo}, Eduardo},
publisher = {JSPerf},
title = {{Typed Arrays Performance}},
url = {http://jsperf.com/typed-arrays-performance},
year = {2013}
}
@misc{Silverlight2013,
abstract = {Silverlight is a powerful development tool for creating engaging, interactive user experiences for Web and mobile applications. Silverlight is a free plug-in, powered by the .NET framework and compatible with multiple browsers, devices and operating systems, bringing a new level of interactivity wherever the Web works.},
author = {Microsoft},
title = {{Silverlight}},
url = {http://www.microsoft.com/silverlight/},
year = {2013}
}
@article{Mckenna1999,
abstract = {The use of adaptive Gaussian mixtures to model the colour distributions of objects is described. These models are used to perform robust, real-time tracking under varying illumination, viewing geometry and amera parameters. Observed log-likelihood measurements were used to perform selective adaptation.},
author = {Mckenna, Stephen J and Raja, Yogesh and Gong, Shaogang},
doi = {10.1016/S0262-8856(98)00104-8},
issn = {02628856},
journal = {Image and Vision Computing},
keywords = {adaptive learning,colour model,gaussian mixture model,real time tracking},
number = {3-4},
pages = {225--231},
title = {{Tracking colour objects using adaptive mixture models}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0262885698001048},
volume = {17},
year = {1999}
}
@misc{WC2006,
abstract = {The World Wide Web Consortium (W3C) is an international community where Member organizations, a full-time staff, and the public work together to develop Web standards. Led by Web inventor Tim Berners-Lee and CEO Jeffrey Jaffe, W3C's mission is to lead the Web to its full potential. Contact W3C for more information.},
author = {{W C}},
booktitle = {W3C},
institution = {W3C},
title = {{The World Wide Web Consortium (W3C)}},
url = {http://www.w3.org/},
year = {2006}
}
@article{Krevelen2010,
abstract = {We are on the verge of ubiquitously adopting Augmented Reality (AR) technologies to enhance our percep- tion and help us see, hear, and feel our environments in new and enriched ways. AR will support us in fields such as education, maintenance, design and reconnaissance, to name but a few. This paper describes the field of AR, including a brief definition and development history, the enabling technologies and their characteristics. It surveys the state of the art by reviewing some recent applications of AR technology as well as some known limitations regarding human factors in the use of AR systems that developers will need to overcome.},
author = {Krevelen, D W F Van and Poelman, R},
doi = {10.1155/2011/721827},
file = {:Users/eduardolundgren/Google Drive/Faculdade/msc-ufpe-thesis/referencias/Krevelen.Reality Technologies.Applications.Limitations.pdf:pdf},
issn = {10255834},
journal = {International Journal},
number = {2},
pages = {1--20},
title = {{A Survey of Augmented Reality Technologies , Applications and Limitations}},
url = {http://www.hindawi.com/journals/jia/2011/721827/},
volume = {9},
year = {2010}
}
@article{Teichrieb2007,
abstract = {This paper surveys the field of Markerless Augmented Reality, specifically online and monocular. This research field is applied by the TechPetro project that aims to define and developed a Markerless Augmented Reality framework for the implementation of Augmented Reality based engineering solutions. In Markerless Augmented Reality, 3D virtual objects are integrated into a 3D real environment in real-time. This is achieved using the world as marker instead of fiducial markers applied in traditional Augmented Reality systems. It discusses major issues related to the field, such as tracking and registration, which become much more complex. This paper also describes the characteristics and experimental results of online monocular Markerless Augmented Reality techniques. Future directions and areas requiring further research are briefly discussed. This survey provides a starting point for anyone interested in researching or using Markerless Augmented Reality.},
author = {Teichrieb, Veronica and Lima, Monte and Lourenc, Eduardo and Bueno, Silva and Kelner, Judith and Santos, Ismael H F},
file = {:Users/eduardolundgren/Google Drive/Faculdade/msc-ufpe-thesis/referencias/VT.Monocular.Markerless.Augmented.Reality.pdf:pdf},
journal = {International Journal of Modeling and Simulation for the Petroleum Industry},
number = {1},
pages = {1--7},
title = {{A Survey of Online Monocular Markerless Augmented Reality}},
url = {http://rpcmod.ganer.ex-br.com/revista/articles/1.pdf},
volume = {1},
year = {2007}
}
@misc{Paschos2001,
abstract = {RGB, a nonuniform color space, is almost universally accepted by the image processing community as the means for representing color. On the other hand, perceptually uniform spaces, such as Lab, as well as approximately-uniform color spaces, such as HSV, exist, in which measured color differences are proportional to the human perception of such differences. This paper compares RGB with Lab and HSV in terms of their effectiveness in color texture analysis. There has been a limited but increasing amount of work on the color aspects of textured images. The results have shown that incorporating color into a texture analysis and recognition scheme can be very important and beneficial. The presented methodology uses a family of Gabor filters specially tuned to measure specific orientations and sizes within each color texture. Effectiveness is measured by the classification performance of each color space, as well as by classifier-independent measures. Experimental results are obtained with a variety of color texture Images. Perceptually uniform spaces are shown to outperform RGB in many cases},
author = {Paschos, G},
booktitle = {IEEE Transactions on Image Processing},
doi = {10.1109/83.923289},
file = {:Users/eduardolundgren/Google Drive/Faculdade/msc-ufpe-thesis/referencias/Paschos.Color.Spaces.pdf:pdf},
issn = {10577149},
number = {6},
pages = {932--937},
title = {{Perceptually uniform color spaces for color texture analysis: an empirical evaluation}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=923289},
volume = {10},
year = {2001}
}
@misc{CMei2008,
abstract = {This paper addresses the problem of motion estimation and 3-D reconstruction through visual tracking with a single-viewpoint sensor and, in particular, how to generalize tracking to calibrated omnidirectional cameras. We analyze different minimization approaches for the intensity-based cost function (sum of squared differences). In particular, we propose novel variants of the efficient second-order minimization (ESM) with better computational complexities and compare these algorithms with the inverse composition (IC) and the hyperplane approximation (HA). Issues regarding the use of the IC and HA for 3-D tracking are discussed. We show that even though an iteration of ESM is computationally more expensive than an iteration of IC, the faster convergence rate makes it globally faster. The tracking algorithm was validated by using an omnidirectional sensor mounted on a mobile robot.},
author = {Mei, C and Benhimane, S and Malis, E and Rives, P},
booktitle = {IEEE Transactions on Robotics},
doi = {10.1109/TRO.2008.2007941},
issn = {15523098},
keywords = {omnidirectional vision,structure from motion,visual tracking},
number = {6},
pages = {1352--1364},
publisher = {IEEE},
title = {{Efficient Homography-Based Tracking and 3-D Reconstruction for Single-Viewpoint Sensors}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4696018},
volume = {24},
year = {2008}
}
@article{Benford1998,
abstract = {We propose an approach to creating shared mixed realities based on the construction of transparent boundaries between real and virtual spaces. First, we introduce a taxonomy that classifies current approaches to shared spaces according to the three dimensions of transportation, artificiality, and spatiality. Second, we discuss our experience of staging a poetry performance simultaneously within real and virtual theaters. This demonstrates the complexities involved in establishing social interaction between real and virtual spaces and motivates the development of a systematic approach to mixing realities. Third, we introduce and demonstrate the technique of mixed-reality boundaries as a way of joining real and virtual spaces together in order to address some of these problems.},
author = {Benford, Steve and Greenhalgh, Chris and Reynard, Gail and Brown, Chris and Koleva, Boriana},
doi = {10.1145/292834.292836},
isbn = {5961401553},
issn = {10730516},
journal = {ACM Transactions on Computer-Human Interaction},
number = {3},
pages = {185--223},
publisher = {ACM},
title = {{Understanding and constructing shared spaces with mixed-reality boundaries}},
url = {http://portal.acm.org/citation.cfm?doid=292834.292836},
volume = {5},
year = {1998}
}
@misc{WebGL2013,
abstract = {This specification describes an additional rendering context and support objects for the HTML 5 canvas element [CANVAS]. This context allows rendering using an API that conforms closely to the OpenGL ES 2.0 API.},
author = {Inc., Apple},
publisher = {Khronos},
title = {{WebGL Specification}},
url = {http://www.khronos.org/registry/webgl/specs/latest/},
year = {2013}
}
@article{RostenFaster2010,
abstract = {The repeatability and efficiency of a corner detector determines how likely it is to be useful in a real-world application. The repeatability is importand because the same scene viewed from different positions should yield features which correspond to the same real-world 3D locations Schmid et al 2000. The efficiency is important because this determines whether the detector combined with further processing can operate at frame rate. Three advances are described in this paper. First, we present a new heuristic for feature detection, and using machine learning we derive a feature detector from this which can fully process live PAL video using less than 5\% of the available processing time. By comparison, most other detectors cannot even operate at frame rate (Harris detector 115\%, SIFT 195\%). Second, we generalize the detector, allowing it to be optimized for repeatability, with little loss of efficiency. Third, we carry out a rigorous comparison of corner detectors based on the above repeatability criterion applied to 3D scenes. We show that despite being principally constructed for speed, on these stringent tests, our heuristic detector significantly outperforms existing feature detectors. Finally, the comparison demonstrates that using machine learning produces significant improvements in repeatability, yielding a detector that is both very fast and very high quality.},
author = {Rosten, Edward and Porter, Reid and Drummond, Tom},
file = {:Users/eduardolundgren/Google Drive/Faculdade/msc-ufpe-thesis/referencias/Rosten.Faster.and.better.PDF:PDF},
institution = {Department of Engineering, Cambridge University, Cambridge, UK. er258@cam.ac.uk},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
number = {1},
pages = {105--119},
publisher = {IEEE},
title = {{Faster and better: a machine learning approach to corner detection}},
url = {http://arxiv.org/abs/0810.2434},
volume = {32},
year = {2010}
}
@article{Cho1998,
abstract = {A - and an Intensity-invariant Detection Method for - (1998) (Make Corrections) (1},
author = {Cho, Y and Lee, J and Neumann, U},
journal = {In IWAR},
keywords = {augmented reality,concentric fiducial,edge detection,fiducial tracking,multi ring fiducial,region segmentation,rule based detection},
pages = {1--15},
title = {{A Multi-ring Color Fiducial System and an Intensity-Invariant Detection Method for Scalable Fiducial-Tracking Augmented Reality}},
url = {http://citeseer.ist.psu.edu/250982.html},
year = {1998}
}
@article{Bradski2000,
abstract = {OpenCV is an open-source, computer-vision library for extracting and processing meaningful data from images. Additional resources include opencv.txt (listings).},
author = {Bradski, G},
journal = {Dr Dobbs Journal of Software Tools},
number = {11},
pages = {120--125},
publisher = {M AND T PUBLISHING INC},
title = {{The OpenCV Library}},
url = {http://opencv.willowgarage.com},
volume = {25},
year = {2000}
}
@phdthesis{Homography2009,
abstract = {This essay has been written to provide the reader with a treatment of homography estimation and its use in today's computer vision applications. The topic is motivated by a discussion of various situations where homography estimation is required and an overview of other geometric transformations so as to situate homographies in the correct context. Various algorithms are discussed ranging from the most basic linear algorithm to statistical optimization. Non-linear algorithms for homography estimation are broken down into the cost functions that they aim to minimize. Robust estimation techniques with respect to outlier correspondences are covered as well as al gorithms making use of non-point correspondences such as lines and conics. Finally, a survey of publicly available software in this area is provided.},
author = {Dubrofsky, Elan},
booktitle = {The University of Britsh Columbia},
file = {:Users/eduardolundgren/Google Drive/Faculdade/msc-ufpe-thesis/referencias/Dubrofsky.Elan.Homography.Estimation.pdf:pdf},
number = {March},
school = {The University of Britsh Columbia},
title = {{Homography Estimation}},
type = {Essay},
year = {2009}
}
@misc{Gecko2013,
abstract = {Gecko is the name of the layout engine developed by the Mozilla Project. It was originally named NGLayout. Gecko's function is to read web content, such as HTML, CSS, XUL, JavaScript, and render it on user's screen or print it. In XUL-based applications Gecko is used to render the application's user interface as well.},
author = {Mozilla, Inc.},
title = {{Gecko}},
url = {https://developer.mozilla.org/en-US/docs/Mozilla/Gecko},
year = {2013}
}
@inproceedings{Sebe2003,
abstract = {Image and video retrieval continues to be one of the most exciting and fastest-growing research areas in the field of multimedia technology. What are the main challenges in image and video retrieval? Despite the sustained efforts in the last years, we think that the paramount challenge remains bridging the semantic gap. By this we mean that low level features are easily measured and computed, but the starting point of the retrieval process is typically the high level query from a human. Translating or converting the question posed by a human to the low level features seen by the computer illustrates the problem in bridging the semantic gap. However, the semantic gap is not merely translating high level features to low level features. The essence of a semantic query is understanding the meaning behind the query. This can involve understanding both the intellectual and emotional sides of the human, not merely the distilled logical portion of the query but also the personal preferences and emotional subtones of the query and the preferential form of the results.Image and video retrieval continues to be one of the most exciting and fastest-growing research areas in the field of multimedia technology. What are the main challenges in image and video retrieval? Despite the sustained efforts in the last years, we think that the paramount challenge remains bridging the semantic gap. By this we mean that low level features are easily measured and computed, but the starting point of the retrieval process is typically the high level query from a human. Translating or converting the question posed by a human to the low level features seen by the computer illustrates the problem in bridging the semantic gap. However, the semantic gap is not merely translating high level features to low level features. The essence of a semantic query is understanding the meaning behind the query. This can involve understanding both the intellectual and emotional sides of the human, not merely the distilled logical portion of the query but also the personal preferences and emotional subtones of the query and the preferential form of the results.},
author = {Sebe, Nicu and Lew, Michael S and Zhou, Xiang and Huang, Thomas S and Bakker, Erwin M},
booktitle = {Image and Video Retrieval},
isbn = {9783540406341},
issn = {03029743},
pages = {1--8},
publisher = {Springer Berlin / Heidelberg},
title = {{The State of the Art in Image and Video Retrieval}},
url = {http://www.springerlink.com/content/u6q89u0y719a8e91/},
volume = {Volume 272},
year = {2003}
}
@misc{Firefox2013,
author = {Mozilla, Inc.},
title = {{Mozilla Firefox Browser}},
url = {http://www.mozilla.org/en-US/firefox/new/},
year = {2013}
}
@misc{JSARToolkit2011,
abstract = {This is a JavaScript port of FLARToolKit, operating on canvas images and video element contents. And hopefully one day on device elements with webcam input.},
author = {Kato, Hirokazu and Billinghurst, Mark},
title = {{JSARToolkit a JavaScript port of FLARToolKit}},
url = {https://github.com/kig/JSARToolKit/},
year = {2011}
}
@misc{WebRTC2013,
abstract = {WebRTC is a free, open project that enables web browsers with Real-Time Communications (RTC) capabilities via simple Javascript APIs. The WebRTC components have been optimized to best serve this purpose.},
author = {Inc., Google and Inc., Mozilla and Inc., Opera},
title = {{WebRTC}},
url = {http://www.webrtc.org/},
year = {2013}
}
@article{Mistry2009,
abstract = {Information is traditionally confined to paper or digitally to a screen. In this paper, we introduce WUW, a wearable gestural interface, which attempts to bring information out into the tangible world. By using a tiny projector and a camera mounted on a hat or coupled in a pendant like wearable device, WUW sees what the user sees and visually augments surfaces or physical objects the user is interacting with. WUW projects information onto surfaces, walls, and physical objects around us, and lets the user interact with the projected information through natural hand gestures, arm movements or interaction with the object itself.},
author = {Mistry, Pranav and Maes, Pattie and Chang, Liyan},
doi = {10.1145/1520340.1520626},
isbn = {9781605582474},
issn = {15552101},
journal = {Proceedings of the 27th international conference extended abstracts on Human factors in computing systems},
keywords = {acm classification keywords,augmented reality,gestural interaction,interface,object augmentation,tangible computing,wearable},
number = {3},
pages = {4111--4116},
pmid = {17388712},
publisher = {ACM},
series = {CHI '09},
title = {{WUW - Wear Ur World - A Wearable Gestural Interface}},
url = {http://portal.acm.org/citation.cfm?id=1520626},
volume = {68},
year = {2009}
}
@article{Lin2009,
abstract = {Accurate 3D registration is a key issue in the Augmented Reality (AR) applications, particularly where are no markers placed manually. In this paper, an efficient markerless registration algorithm is presented for both outdoor and indoor AR system. This algorithm first calculates the correspondences among frames using fixed region tracking, and then estimates the motion parameters on projective transformation following the homography of the tracked region. To achieve the illumination insensitive tracking, the illumination parameters are solved jointly with motion parameters in each step. Based on the perspective motion parameters of the tracked region, the 3D registration, the camera's pose and position, can be calculated with calibrated intrinsic parameters. A marker-less AR system is described using this algorithm, and the system architecture and working flow are also proposed. Experimental results with comparison quantitatively demonstrate the correctness of the theoretical analysis and the robustness of the registration algorithm.},
author = {Lin, Liang and Wang, Yongtian and Liu, Yue and Xiong, Caiming and Zeng, Kun},
doi = {10.1007/s11042-008-0227-y},
issn = {13807501},
journal = {Multimedia Tools and Applications},
keywords = {augmented reality,marker less registration,virtual tracking},
number = {2},
pages = {235--252},
title = {{Marker-less registration based on template tracking for augmented reality}},
url = {http://www.springerlink.com/index/10.1007/s11042-008-0227-y},
volume = {41},
year = {2009}
}
@misc{Canvas2013,
abstract = {The canvas element provides scripts with a resolution-dependent bitmap canvas, which can be used for rendering graphs, game graphics, art, or other visual images on the fly.},
author = {Community, WHATWG},
publisher = {WHATWG Community},
title = {{The canvas element}},
url = {http://www.whatwg.org/specs/web-apps/current-work/multipage/the-canvas-element.html},
year = {2013}
}
@article{Calonder2010,
abstract = {We propose to use binary strings as an efficient feature point descriptor, which we call BRIEF.We show that it is highly discriminative even when using relatively few bits and can be computed using simple intensity difference tests. Furthermore, the descriptor similarity can be evaluated using the Hamming distance, which is very efficient to compute, instead of the L 2 norm as is usually done. As a result, BRIEF is very fast both to build and to match. We compare it against SURF and U-SURF on standard benchmarks and show that it yields a similar or better recognition performance, while running in a fraction of the time required by either.},
author = {Calonder, Michael and Lepetit, Vincent and Strecha, Christoph and Fua, Pascal},
chapter = {56},
doi = {10.1007/978-3-642-15561-1\_56},
editor = {Daniilidis, Kostas and Maragos, Petros and Paragios, Nikos},
file = {:Users/eduardolundgren/Google Drive/Faculdade/msc-ufpe-thesis/referencias/Lepetit.BRIEF.pdf:pdf},
isbn = {9783642155604},
issn = {07364679},
journal = {Computer},
number = {3},
pages = {778--792},
pmid = {19500939},
publisher = {Springer},
series = {Lecture Notes in Computer Science},
title = {{BRIEF : Binary Robust Independent Elementary Features}},
url = {http://www.springerlink.com/index/H8H1824827036042.pdf},
volume = {6314},
year = {2010}
}
@article{Lepetit2005,
abstract = {Many applications require tracking of complex 3D objects. These include visual servoing of robotic arms on specific target objects, Augmented Reality systems that require real-time registration of the object to be augmented, and head tracking systems that sophisticated interfaces can use. Computer Vision offers solutions that are cheap, practical and non-invasive. This survey reviews the different techniques and approaches that have been developed by industry and research. First, important mathematical tools are introduced: Camera representation, robust estimation and uncertainty estimation. Then a comprehensive study is given of the numerous approaches developed by the Augmented Reality and Robotics communities, beginning with those that are based on point or planar fiducial marks and moving on to those that avoid the need to engineer the environment by relying on natural features such as edges, texture or interest. Recent advances that avoid manual initialization and failures due to fast motion are also presented. The survery concludes with the different possible choices that should be made when implementing a 3D tracking system and a discussion of the future of vision-based 3D tracking. Because it encompasses many computer vision techniques from lowlevel vision to 3D geometry and includes a comprehensive study of the massive literature on the subject, this survey should be the handbook of the student, the researcher, or the engineer who wants to implement a 3D tracking system.},
author = {Lepetit, Vincent and Fua, Pascal},
doi = {10.1561/0600000001},
file = {:Users/eduardolundgren/Google Drive/Faculdade/msc-ufpe-thesis/referencias/Lepetit.Monocular.Model.Based.3D.Tracking.pdf:pdf},
isbn = {1933019034},
issn = {15722740},
journal = {Foundations and Trends® in Computer Graphics and Vision},
number = {1},
pages = {1--89},
publisher = {Now Publishers Inc},
series = {Foundation. Trends Comput. Graph. Vis. (USA)},
title = {{Monocular Model-Based 3D Tracking of Rigid Objects}},
url = {http://www.nowpublishers.com/product.aspx?product=CGV\&doi=0600000001},
volume = {1},
year = {2005}
}
@inproceedings{Gloyer1994,
abstract = {An image processing and object tracking approach is proposed for the design of a video-based freeway traffic monitoring system. Proper estimation of the traffic speed in different lanes of a freeway allows for timely detection of possible congestions. The proposed method consists of a road modeling stage and a vehicle tracking stage. In the first stage, a three-dimensional model of the background road image is generated. In the tracking stage, each car in the scene is isolated and tracked over many frames. Experimental results on frame sequences taken},
author = {Gloyer, B and Aghajan, H K and Siu, Kai Yeung and Kailath, T},
booktitle = {Asilomar Conference on Signals Systems and Computers},
pages = {970--974},
title = {{Vehicle detection and tracking for freeway traffic monitoring}},
volume = {2},
year = {1994}
}
@book{Hartley2004,
abstract = {A basic problem in computer vision is to understand the structure of a real world scene. This book covers relevant geometric principles and how to represent objects algebraically so they can be computed and applied. Recent major developments in the theory and practice of scene reconstruction are described in detail in a unified framework. Richard Hartley and Andrew Zisserman provide comprehensive background material and explain how to apply the methods and implement the algorithms.},
author = {Hartley, Richard and Zisserman, Andrew},
booktitle = {Cambridge University Press},
chapter = {189},
isbn = {0521540518},
issn = {05215405},
number = {2},
pages = {672},
publisher = {Cambridge University Press},
title = {{Multiple View Geometry in Computer Vision}},
url = {http://www.robots.ox.ac.uk/~vgg/hzbook/},
volume = {2},
year = {2004}
}
@misc{Bray2013,
abstract = {The Extensible Markup Language (XML) is a subset of SGML that is completely described in this document. Its goal is to enable generic SGML to be served, received, and processed on the Web in the way that is now possible with HTML. XML has been designed for ease of implementation and for interoperability with both SGML and HTML.},
author = {Bray, Tim},
title = {{Extensible Markup Language (XML)}},
year = {2013}
}
@article{Kravtchenko1999,
author = {Kravtchenko, Vladimir},
file = {:Users/eduardolundgren/Google Drive/Faculdade/msc-ufpe-thesis/referencias/Kravtchenko.Color.Tracking.Master.Thesis.pdf:pdf},
title = {{Tracking Color Objects in Real Time}},
year = {1999}
}
@misc{WebKit2013,
abstract = {WebKit is an open source web browser engine. WebKit is also the name of the Mac OS X system framework version of the engine that's used by Safari, Dashboard, Mail, and many other OS X applications. WebKit's HTML and JavaScript code began as a branch of the KHTML and KJS libraries from KDE.},
author = {Inc., Apple},
title = {{The WebKit Open Source Project}},
url = {http://www.webkit.org/},
year = {2013}
}
@misc{TypedArray2013,
abstract = {This specification provides an API for interoperability with native binary data. It defines a generic fixed-length buffer type, as well as accessor types that allow access to the data stored within the buffer.},
author = {Herman, David and Russell, Kenneth},
publisher = {Khronos},
title = {{Typed Array Specification}},
url = {http://www.khronos.org/registry/typedarray/specs/latest/},
year = {2013}
}
@inproceedings{Viola2001,
author = {Viola, P. and Jones, M.},
booktitle = {Proceedings of the 2001 IEEE Computer Society Conference on Computer Vision and Pattern Recognition. CVPR 2001},
doi = {10.1109/CVPR.2001.990517},
file = {:Users/eduardolundgren/Google Drive/Faculdade/msc-ufpe-thesis/referencias/Viola.Jones.pdf:pdf},
isbn = {0-7695-1272-0},
pages = {I--511--I--518},
publisher = {IEEE Comput. Soc},
title = {{Rapid object detection using a boosted cascade of simple features}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=990517},
volume = {1},
year = {2001}
}
@article{Crockford2013,
author = {Crockford, Douglas},
title = {{JSON}},
year = {2013}
}
@book{piegl1993fundamental,
author = {Piegl, Les A},
publisher = {Academic Pr},
title = {{Fundamental developments of computer-aided geometric modeling}},
year = {1993}
}
@misc{AAC2006,
abstract = {Advanced Audio Coding (AAC) is a standardized, lossy compression and encoding scheme for digital audio. Designed to be the successor of the MP3 format, AAC generally achieves better sound quality than MP3 at similar bit rates.},
author = {ISO},
title = {{Information technology -- Generic coding of moving pictures and associated audio information -- Part 7: Advanced Audio Coding (AAC)}},
year = {2006}
}
@article{black2007big,
author = {Black, Paul E},
journal = {Dictionary of Algorithms and Data Structures},
title = {{Big-O Notation}},
year = {2007}
}
@article{Yilmaz2006,
abstract = {The goal of this article is to review the state-of-the-art tracking methods, classify them into different categories, and identify new trends. Object tracking, in general, is a challenging problem. Difficulties in tracking objects can arise due to abrupt object motion, changing appearance patterns of both the object and the scene, nonrigid object structures, object-to-object and object-to-scene occlusions, and camera motion. Tracking is usually performed in the context of higher-level applications that require the location and/or shape of the object in every frame. Typically, assumptions are made to constrain the tracking problem in the context of a particular application. In this survey, we categorize the tracking methods on the basis of the object and motion representations used, provide detailed descriptions of representative methods in each category, and examine their pros and cons. Moreover, we discuss the important issues related to tracking including the use of appropriate image features, selection of motion models, and detection of objects.},
author = {Yilmaz, Alper and Javed, Omar and Shah, Mubarak},
doi = {10.1145/1177352.1177355},
editor = {Goszczynska, Hanna},
file = {:Users/eduardolundgren/Google Drive/Faculdade/msc-ufpe-thesis/referencias/Yilmaz.Object.Tracking.pdf:pdf},
institution = {University of Central Florida},
isbn = {9789533073606},
issn = {03600300},
journal = {ACM Computing Surveys},
number = {4},
pages = {13},
publisher = {ACM},
title = {{Object tracking: A survey}},
url = {http://portal.acm.org/citation.cfm?doid=1177352.1177355},
volume = {38},
year = {2006}
}
@article{Hirokazu2002,
abstract = {In this paper, I introduce ARToolKit and describe about the structure and what we can do with ARToolKit. ARToolKit is a library which is useful to make vision-based Augmented Reality applications. It is distributed as an open source library. ARToolKit uses black square markers with unique pattern in it and calculates pose and position of the marker. Then virtual objects can be drawn in the marker coordinates and geometrical consistency between real world and the virtual objects is maintained in spite of user's view point.},
author = {Hirokazu, Kato},
journal = {IEIC Technical Report Institute of Electronics Information and Communication Engineers},
number = {652(PRMU2001 222-232)},
pages = {79--86},
title = {{ARToolKit: Library for Vision-based Augmented Reality.}},
volume = {101},
year = {2002}
}
@book{Gonzalez2007,
abstract = {THE leader in the field for more than twenty years, this introduction to basic concepts and methodologies for digital image processing continues its cutting-edge focus on contemporary developments in all mainstream areas of image processing. Completely self-contained, heavily illustrated, and mathematically accessible, it has a scope of application that is not limited to the solution of specialized problems. Digital Image Fundamentals. Image Enhancement in the Spatial Domain. Image Enhancement in the Frequency Domain. Image Restoration. Color Image Processing. Wavelets and Multiresolution Processing. Image Compression. Morphological Image Processing. Image Segmentation. Representation and Description. Object Recognition. For technicians interested in the fundamentals and contemporary applications of digital imaging processing},
author = {Gonzalez, Rafael C and Woods, Richard E},
booktitle = {3nd edition},
isbn = {013168728X},
pages = {976},
publisher = {Prentice Hall},
title = {{Digital Image Processing (3rd Edition)}},
url = {http://www.amazon.ca/exec/obidos/redirect?tag=citeulike09-20\&amp;path=ASIN/013168728X},
year = {2007}
}
@article{Lima2009a,
abstract = {This paper presents an implementation of a markerless tracking technique targeted to the Windows Mobile Pocket PC platform. The primary aim of this work is to allow the development of standalone augmented reality applications for handheld devices based on natural feature tracking. In order to achieve this goal, a subset of two computer vision libraries was ported to the Pocket PC platform. They were also adapted to use fixed point math, with the purpose of improving the overall performance of the routines. The port of these libraries opens up the possibility of having other computer vision tasks being executed on mobile platforms. A model based tracking approach that relies on edge information was adopted. Since it does not require a high processing power, it is suitable for constrained devices such as handhelds. The OpenGL ES graphics library was used to perform computer vision tasks, taking advantage of existing graphics hardware acceleration. An augmented reality application was created using the implemented technique and evaluations were done regarding tracking performance and accuracy},
author = {Lima, Joao Paulo and Teichrieb, Veronica and Kelner, Judith},
journal = {Virtual Reality},
keywords = {augmented reality,computer vision,handheld,markerless tracking},
pages = {1--15},
title = {{A Standalone Markerless 3D Tracker for Handheld Augmented Reality}},
url = {http://arxiv.org/abs/0902.2187},
year = {2009}
}
@article{Kalal2011,
abstract = {This paper investigates long-term tracking of unknown objects in a video stream. The object is defined by its location and extent in a single frame. In every frame that follows, the task is to determine the object's location and extent or indicate that the object is not present. We propose a novel tracking framework (TLD) that explicitly decomposes the long-term tracking task into tracking, learning and detection. The tracker follows the object from frame to frame. The detector localizes all appearances that have been observed so far and corrects the tracker if necessary. The learning estimates detector's errors and updates it to avoid these errors in the future. We study how to identify detector's errors and learn from them. We develop a novel learning method (P-N learning) which estimates the errors by a pair of "experts'': (i) P-expert estimates missed detections, and (ii) N-expert estimates false alarms. The learning process is modeled as a discrete dynamical system and the conditions under which the learning guarantees improvement are found. We describe our real-time implementation of the TLD framework and the P-N learning. We carry out an extensive quantitative evaluation which shows a significant improvement over state-of-the-art approaches.},
author = {Kalal, Zdenek and Mikolajczyk, Krystian and Matas, Jiri},
doi = {10.1109/TPAMI.2011.239},
file = {:Users/eduardolundgren/Google Drive/Faculdade/msc-ufpe-thesis/referencias/Zdenek.Tracking.Learning.Detection.pdf:pdf},
isbn = {2011030153},
issn = {1939-3539},
journal = {IEEE transactions on pattern analysis and machine intelligence},
month = dec,
number = {7},
pages = {1409--1422},
pmid = {22156098},
title = {{Tracking-Learning-Detection.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/22156098},
volume = {34},
year = {2011}
}
@article{Jia2009,
abstract = {Abstract: This paper surveys the developments of the last 10 years in the area of vision based target tracking for autonomous vehicles navigation. First, the motivations and existing applications of using vision based target tracking for autonomous vehicles navigation are discussed in the introduction section 1. It can be concluded that it is very necessary to develop robust visual target tracking based navigation algorithms for the broad applications of autonomous vehicles 2. Then this paper reviews the recent techniques in vision based target tracking for the applications of autonomous land vehicle navigation. Next the increasing trends of using data fusion for visual target tracking 3 based autonomous vehicles navigation are discussed. It is clear that through data fusion the tracking performance is improved and becomes more robust. Based on the reviews, the remaining research challenges are summarized and future research directions are investigated.},
author = {Jia, Zhen and Balasuriya, Arjuna and Challa, Subhash},
doi = {10.2174/1874479600902010032},
issn = {18744796},
journal = {Recent Patents on Computer Science},
keywords = {autonomous vehicles,computer vision,mobile robots,navigation,sensor data fusion,target tracking},
number = {1},
pages = {32--42},
title = {{Vision Based Target Tracking for Autonomous Land Vehicle Navigation: A Brief Survey}},
url = {http://www.bentham-direct.org/pages/content.php?CSENG/2009/00000002/00000001/0004CSENG.SGM},
volume = {2},
year = {2009}
}
@misc{Riemersma2010,
author = {Riemersma, Thiadmer},
title = {{Colour metric}},
url = {http://www.compuphase.com/cmetric.htm},
year = {2010}
}
@misc{Blink2013,
abstract = {Blink is the rendering engine used by Chromium.},
author = {Inc., Google},
title = {{Blink}},
url = {http://www.chromium.org/blink},
year = {2013}
}
@misc{Glass2013,
author = {Inc., Google},
title = {{Project Glass}},
url = {http://www.google.com/glass/start/},
year = {2013}
}
@article{Cedras1995,
abstract = {Motion-based recognition deals with the recognition of an object or its motion based on motion in a sequence of images. In this approach, a sequence containing a large number of frames is used to extract motion information. The advantage is that a longer sequence leads to recognition of higher level motions, like walking or running, which consists of a complex and coordinated series of events that cannot be understood by looking at only a few frames. This paper provides a review of recent developments in the computer vision aspect of motion-based recognition. We will identify two main steps in motion-based recognition. The first step is the extraction of motion information and its organization into motion models. The second step consists of the matching of some unknown input with a constructed model. Several methods for the recognition of objects and motions will then be reported. They include methods such as cyclic motion detection and recognition, lipreading, hand gestures interpretation, motion verb recognition and temporal textures classification. Tracking and recognition of human motion, like walking, skipping and running will also be discussed. Finally, we will conclude the paper with some thoughts about future directions for motion-based recognition.},
author = {Cedras, C and Shah, M},
doi = {10.1016/0262-8856(95)93154-k},
issn = {02628856},
journal = {Image and Vision Computing},
number = {2},
pages = {129--155},
title = {{MOTION-BASED RECOGNITION - A SURVEY}},
volume = {13},
year = {1995}
}
@misc{MediaCapture2013,
abstract = {This document defines a set of JavaScript APIs that allow local media, including audio and video, to be requested from a platform.},
author = {{Daniel C. Burnett}, Voxeo and {Adam Bergkvist}, Ericsson and {Cullen Jennings}, Cisco and Narayanan, Anant},
publisher = {W3C},
title = {{Media Capture and Streams}},
url = {http://www.w3.org/TR/mediacapture-streams/},
year = {2013}
}
@article{Teichrieb2010,
author = {Lima, Jo\~{a}o Paulo and Sim\~{o}es, Francisco and Figueiredo, Lucas and Kelner, Judith},
file = {:Users/eduardolundgren/Google Drive/Faculdade/msc-ufpe-thesis/referencias/VT.Model.Based.Markerless.3D.Tracking.applied.to.Augmented Reality.pdf:pdf},
pages = {2--15},
title = {{Model Based Markerless 3D Tracking applied to Augmented Reality}},
volume = {1},
year = {2010}
}
@article{Joma2013,
author = {{Xavier Natario Teixeira}, Joao Marcelo},
file = {:Users/eduardolundgren/Google Drive/Faculdade/msc-ufpe-thesis/referencias/Joma.PhD.pdf:pdf},
title = {{Analysis and Evaluation of Optimization Techniques for Tracking in Augmented Reality Applications}},
year = {2013}
}
@misc{Hickson2013,
abstract = {This specification defines the 5th major version, first minor revision of the core language of the World Wide Web: the Hypertext Markup Language (HTML). In this version, new features continue to be introduced to help Web application authors, new elements continue to be introduced based on research into prevailing authoring practices, and special attention continues to be given to defining clear conformance criteria for user agents in an effort to improve interoperability.},
author = {Hickson, Ian},
publisher = {W3C},
title = {{HTML 5 Nightly Specification (W3C)}},
url = {http://www.w3.org/html/wg/drafts/html/master/},
year = {2013}
}
@misc{Li2008,
abstract = {The appearances of the tracked object and its surrounding background usually change during tracking. As for tracking methods using subspace analysis, fixed subspace basis tends to cause tracking failure. In this paper, a novel tracking method is proposed by using incremental 2D-LDA learning and Bayes inference. Incremental 2D-LDA formulates object tracking as online classification between foreground and background. It updates the row- or/and column- projected matrix efficiently. Based on the current object location and the prior knowledge, the possible locations of the object (candidates) in the next frame are predicted using simple sampling method. Applying 2D-LDA projection matrix and Bayes inference, candidate that maximizes the posterior probability is selected as the target object. Moreover, informative background samples are selected to update the subspace basis. Experiments are performed on image sequences with the object's appearance variations due to pose, lighting, etc. We also make comparison to incremental 2D-PCA and incremental FDA. The experimental results demonstrate that the proposed method is efficient and outperforms both the compared methods.},
author = {Li, Guorong Li Guorong and Liang, Dawei Liang Dawei and Huang, Qingming Huang Qingming and Jiang, Shuqiang Jiang Shuqiang and Gao, Wen Gao Wen},
booktitle = {2008 15th IEEE International Conference on Image Processing},
doi = {10.1109/ICIP.2008.4712068},
isbn = {9781424417650},
issn = {15224880},
keywords = {bayes inference,incremental 2d lda,object tracking},
pages = {1568--1571},
publisher = {Ieee},
title = {{Object tracking using incremental 2D-LDA learning and Bayes inference}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4712068},
year = {2008}
}
@misc{Safari2013,
abstract = {Safari Web Browser},
author = {Inc., Apple},
title = {{Safari Browser}},
url = {http://www.apple.com/safari/},
year = {2013}
}
@article{Metaio2009,
author = {Inc., Metaio},
title = {{Metaio Unifeye Viewer}},
url = {http://docs.metaio.com/bin/view/Main/UnifeyeViewer},
year = {2009}
}
@article{Rocks2013,
abstract = {HTML5 is the ubiquitous platform for the web. Whether you're a mobile web developer, an enterprise with specific business needs, or a serious game dev looking to explore the web as a new platform, HTML5 has something for you.},
author = {Inc., Google},
title = {{HTML5 Rocks Tutorials}},
url = {http://www.html5rocks.com/},
year = {2013}
}
@misc{Flash2013,
abstract = {Adobe Flash Player is the standard for delivering high-impact, rich Web content. Designs, animation, and application user interfaces are deployed immediately across all browsers and platforms, attracting and engaging users with a rich Web experience.},
author = {Inc., Adobe},
title = {{Adobe Flash}},
url = {http://www.adobe.com/software/flash/about/},
year = {2013}
}
@misc{Theora2011,
abstract = {Theora is a general purpose, lossy video codec.},
author = {{Xiph.Org Foundation}},
title = {{Theora Specification}},
url = {http://theora.org/doc/Theora.pdf},
year = {2011}
}
@misc{Intel2007,
abstract = {Intel® Streaming SIMD Extensions 4 (SSE4) introduces 54 new instructions in Intel 64 processors made from 45 nm process technology},
author = {Corporation, Intel},
title = {{Intel® SSE4 Programming Reference}},
url = {http://software.intel.com/file/18187},
year = {2007}
}
@article{Javed2002,
abstract = {In this paper we discuss the issues that need to be resolved before fully automated outdoor surveillance systems can be developed, and present solutions to some of these problems. Any outdoor surveillance system must be able to track objects moving in its field of view, classify these objects and detect some of their activities. We have developed a method to track and classify these objects in realistic scenarios.},
author = {Javed, Omar and Shah, Mubarak},
doi = {10.1.1.4.4406},
isbn = {3540437487},
journal = {History},
pages = {343--357},
publisher = {Springer},
title = {{Tracking and object classification for automated surveillance}},
url = {http://www.springerlink.com/index/U6Y8DLF9RE6KRFW1.pdf},
volume = {26},
year = {2002}
}
@article{Pablo2013,
author = {Paulo, Jo\~{a}o and Lima, S M and Pinheiro, Pablo C and Teichrieb, Veronica and Kelner, Judith},
file = {:Users/eduardolundgren/Google Drive/Faculdade/msc-ufpe-thesis/referencias/Pablo.SVR.AR.web.pdf:pdf},
title = {{Markerless Tracking Solutions for Augmented Reality on the Web}}
}
@article{Ren2010,
abstract = {Computer vision techniques have been widely applied to immersive and perceptual human-computer interaction for applications like computer gaming, education, and entertainment. In this paper, relevant techniques are surveyed in terms of image capturing, normalization, motion detection, tracking, feature representation and recognition. In addition, applications of vision techniques in HCI in computer gaming are also summarized in several categories including vision enabled pointing and positioning, vision for manipulating objects, training and education, and miscellaneous applications. The characteristics of existing work are analyzed and discussed, along with corresponding challenges and future research directions proposed.},
author = {Ren, Jinchang Ren Jinchang and Vlachos, T and Argyriou, V},
journal = {Computer Vision and Pattern Recognition Workshops CVPRW 2010 IEEE Computer Society Conference on},
pages = {66--72},
title = {{Immersive and perceptual human-computer interaction using computer vision techniques}},
url = {http://dx.doi.org/10.1109/CVPRW.2010.5543161},
year = {2010}
}
@misc{Yan2011,
abstract = {Currently most technologies used by virtual studio systems are extended applications of Virtual Reality (VR) technologies. But for small TV stations and web stations, virtual studio based on traditional VR is so expensive while the FLARToolKit technology used by Augmented Reality (AR) technologies is their top option. However, the calculation speed of FLARToolKit is a little slow and the frame rate is very difficult to reach the live broadcasting video level. My improvements are to apply adaptive thresholds, use sample blurring and change identification frequency, which solves the shortcomings and makes the Virtual Studio faster and better.},
author = {Yan, Yongxin and Zhang, Xiaolei},
booktitle = {2011 International Conference on Mechatronic Science Electric Engineering and Computer MEC},
doi = {10.1109/MEC.2011.6025786},
file = {:Users/eduardolundgren/Google Drive/Faculdade/msc-ufpe-thesis/referencias/Yan.FLARToolKit.pdf:pdf},
institution = {International School, Beijing University of Posts and Telecommunications, Beijing, China},
isbn = {9781612847214},
keywords = {adaptive thresholds,augmented reality (ar),flartoolkit,sample blurring},
pages = {1614--1617},
publisher = {IEEE},
title = {{Research and analysis of the Virtual Reality with FLARToolKit}},
year = {2011}
}
@misc{Chrome2010,
abstract = {Google Chrome is a freeware web browser developed by Google that uses the WebKit layout engine. It was first released as a beta version for Microsoft Windows on September 2, 2008, and the public stable release was on December 11, 2008. As of January 2012update, Google Chrome has approximately 2528\% worldwide usage share of web browsers, making it the second or the third most widely used browser, according to different estimates.1234 Google web browsers, Chrome + Android web browser, are now used more on wikimedia than any other browser.5},
author = {Inc., Google},
booktitle = {Group},
pages = {1--5},
publisher = {Google, Inc.},
title = {{Google Chrome Browser}},
url = {https://www.google.com/chrome},
year = {2010}
}
@book{Impa2009,
author = {Gomes, Jonas and Velho, Luiz},
isbn = {978-85-244-0200-5},
title = {{Fundamentos da Computa\c{c}\~{a}o Gr\'{a}fica}},
year = {2009}
}
