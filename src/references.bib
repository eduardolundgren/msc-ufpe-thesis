Automatically generated by Mendeley 1.8.4
Any changes to this file will be lost if it is regenerated by Mendeley.

@article{Teichrieb2010,
author = {Lima, Jo\~{a}o Paulo and Sim\~{o}es, Francisco and Figueiredo, Lucas and Kelner, Judith},
file = {:Users/eduardolundgren/Google Drive/Faculdade/msc-ufpe-thesis/referencias/VT.Model.Based.Markerless.3D.Tracking.applied.to.Augmented Reality.pdf:pdf},
pages = {2--15},
title = {{Model Based Markerless 3D Tracking applied to Augmented Reality}},
volume = {1},
year = {2010}
}
@misc{JSARToolkit2011,
abstract = {This is a JavaScript port of FLARToolKit, operating on canvas images and video element contents. And hopefully one day on device elements with webcam input.},
author = {Kato, Hirokazu and Billinghurst, Mark},
title = {{JSARToolkit a JavaScript port of FLARToolKit}},
url = {https://github.com/kig/JSARToolKit/},
year = {2011}
}
@article{Benford1998,
abstract = {We propose an approach to creating shared mixed realities based on the construction of transparent boundaries between real and virtual spaces. First, we introduce a taxonomy that classifies current approaches to shared spaces according to the three dimensions of transportation, artificiality, and spatiality. Second, we discuss our experience of staging a poetry performance simultaneously within real and virtual theaters. This demonstrates the complexities involved in establishing social interaction between real and virtual spaces and motivates the development of a systematic approach to mixing realities. Third, we introduce and demonstrate the technique of mixed-reality boundaries as a way of joining real and virtual spaces together in order to address some of these problems.},
author = {Benford, Steve and Greenhalgh, Chris and Reynard, Gail and Brown, Chris and Koleva, Boriana},
doi = {10.1145/292834.292836},
isbn = {5961401553},
issn = {10730516},
journal = {ACM Transactions on Computer-Human Interaction},
number = {3},
pages = {185--223},
publisher = {ACM},
title = {{Understanding and constructing shared spaces with mixed-reality boundaries}},
url = {http://portal.acm.org/citation.cfm?doid=292834.292836},
volume = {5},
year = {1998}
}
@misc{TypedArray2013,
abstract = {This specification provides an API for interoperability with native binary data. It defines a generic fixed-length buffer type, as well as accessor types that allow access to the data stored within the buffer.},
author = {Herman, David and Russell, Kenneth},
publisher = {Khronos},
title = {{Typed Array Specification}},
url = {http://www.khronos.org/registry/typedarray/specs/latest/},
year = {2013}
}
@article{Mistry2009,
abstract = {Information is traditionally confined to paper or digitally to a screen. In this paper, we introduce WUW, a wearable gestural interface, which attempts to bring information out into the tangible world. By using a tiny projector and a camera mounted on a hat or coupled in a pendant like wearable device, WUW sees what the user sees and visually augments surfaces or physical objects the user is interacting with. WUW projects information onto surfaces, walls, and physical objects around us, and lets the user interact with the projected information through natural hand gestures, arm movements or interaction with the object itself.},
author = {Mistry, Pranav and Maes, Pattie and Chang, Liyan},
doi = {10.1145/1520340.1520626},
isbn = {9781605582474},
issn = {15552101},
journal = {Proceedings of the 27th international conference extended abstracts on Human factors in computing systems},
keywords = {acm classification keywords,augmented reality,gestural interaction,interface,object augmentation,tangible computing,wearable},
number = {3},
pages = {4111--4116},
pmid = {17388712},
publisher = {ACM},
series = {CHI '09},
title = {{WUW - Wear Ur World - A Wearable Gestural Interface}},
url = {http://portal.acm.org/citation.cfm?id=1520626},
volume = {68},
year = {2009}
}
@article{CSS2013,
abstract = {This page contains descriptions of all specifications that the CSS WG is working on.},
author = {W3C},
title = {{Descriptions of all CSS specifications}},
url = {http://www.w3.org/Style/CSS/specs.en.html},
year = {2013}
}
@book{Gonzalez2007,
abstract = {THE leader in the field for more than twenty years, this introduction to basic concepts and methodologies for digital image processing continues its cutting-edge focus on contemporary developments in all mainstream areas of image processing. Completely self-contained, heavily illustrated, and mathematically accessible, it has a scope of application that is not limited to the solution of specialized problems. Digital Image Fundamentals. Image Enhancement in the Spatial Domain. Image Enhancement in the Frequency Domain. Image Restoration. Color Image Processing. Wavelets and Multiresolution Processing. Image Compression. Morphological Image Processing. Image Segmentation. Representation and Description. Object Recognition. For technicians interested in the fundamentals and contemporary applications of digital imaging processing},
author = {Gonzalez, Rafael C and Woods, Richard E},
booktitle = {3nd edition},
isbn = {013168728X},
pages = {976},
publisher = {Prentice Hall},
title = {{Digital Image Processing (3rd Edition)}},
url = {http://www.amazon.ca/exec/obidos/redirect?tag=citeulike09-20\&amp;path=ASIN/013168728X},
year = {2007}
}
@misc{Safari2013,
abstract = {Safari Web Browser},
author = {Inc., Apple},
title = {{Safari Browser}},
url = {http://www.apple.com/safari/},
year = {2013}
}
@book{piegl1993fundamental,
author = {Piegl, Les A},
publisher = {Academic Pr},
title = {{Fundamental developments of computer-aided geometric modeling}},
year = {1993}
}
@misc{Intel2007,
abstract = {Intel® Streaming SIMD Extensions 4 (SSE4) introduces 54 new instructions in Intel 64 processors made from 45 nm process technology},
author = {Corporation, Intel},
title = {{Intel® SSE4 Programming Reference}},
url = {http://software.intel.com/file/18187},
year = {2007}
}
@misc{Flash2013,
abstract = {Adobe Flash Player is the standard for delivering high-impact, rich Web content. Designs, animation, and application user interfaces are deployed immediately across all browsers and platforms, attracting and engaging users with a rich Web experience.},
author = {Inc., Adobe},
title = {{Adobe Flash}},
url = {http://www.adobe.com/software/flash/about/},
year = {2013}
}
@article{Cho1998,
abstract = {A - and an Intensity-invariant Detection Method for - (1998) (Make Corrections) (1},
author = {Cho, Y and Lee, J and Neumann, U},
journal = {In IWAR},
keywords = {augmented reality,concentric fiducial,edge detection,fiducial tracking,multi ring fiducial,region segmentation,rule based detection},
pages = {1--15},
title = {{A Multi-ring Color Fiducial System and an Intensity-Invariant Detection Method for Scalable Fiducial-Tracking Augmented Reality}},
url = {http://citeseer.ist.psu.edu/250982.html},
year = {1998}
}
@misc{Blink2013,
abstract = {Blink is the rendering engine used by Chromium.},
author = {Inc., Google},
title = {{Blink}},
url = {http://www.chromium.org/blink},
year = {2013}
}
@article{Metaio2009,
author = {Inc., Metaio},
title = {{Metaio Unifeye Viewer}},
url = {http://docs.metaio.com/bin/view/Main/UnifeyeViewer},
year = {2009}
}
@misc{WebKit2013,
abstract = {WebKit is an open source web browser engine. WebKit is also the name of the Mac OS X system framework version of the engine that's used by Safari, Dashboard, Mail, and many other OS X applications. WebKit's HTML and JavaScript code began as a branch of the KHTML and KJS libraries from KDE.},
author = {Inc., Apple},
title = {{The WebKit Open Source Project}},
url = {http://www.webkit.org/},
year = {2013}
}
@article{Rocks2013,
abstract = {HTML5 is the ubiquitous platform for the web. Whether you're a mobile web developer, an enterprise with specific business needs, or a serious game dev looking to explore the web as a new platform, HTML5 has something for you.},
author = {Inc., Google},
title = {{HTML5 Rocks Tutorials}},
url = {http://www.html5rocks.com/},
year = {2013}
}
@misc{Glass2013,
author = {Inc., Google},
title = {{Project Glass}},
url = {http://www.google.com/glass/start/},
year = {2013}
}
@article{Zhou2008,
abstract = {Although Augmented Reality technology was first developed over forty years ago, there has been little survey work giving an overview of recent research in the field. This paper reviews the ten-year development of the work presented at the ISMAR conference and its predecessors with a particular focus on tracking, interaction and display research. It provides a roadmap for future augmented reality research which will be of great value to this relatively young field, and also for helping researchers decide which topics should be explored when they are beginning their own studies in the area.},
author = {Zhou, Feng and Duh, Henry Been-lirn and Billinghurst, Mark},
doi = {10.1109/ISMAR.2008.4637362},
editor = {Livingston, Mark A and Bimber, Oliver and Saito, Hideo},
file = {:Users/eduardolundgren/Google Drive/Faculdade/msc-ufpe-thesis/referencias/Zhou.Trends in Augmented.Reality.Tracking.pdf:pdf},
isbn = {9781424428403},
journal = {2008 7th IEEEACM International Symposium on Mixed and Augmented Reality},
number = {4},
pages = {193--202},
publisher = {Ieee},
series = {ISMAR '08},
title = {{Trends in augmented reality tracking, interaction and display: A review of ten years of ISMAR}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4637362},
volume = {2},
year = {2008}
}
@article{Hirokazu2002,
abstract = {In this paper, I introduce ARToolKit and describe about the structure and what we can do with ARToolKit. ARToolKit is a library which is useful to make vision-based Augmented Reality applications. It is distributed as an open source library. ARToolKit uses black square markers with unique pattern in it and calculates pose and position of the marker. Then virtual objects can be drawn in the marker coordinates and geometrical consistency between real world and the virtual objects is maintained in spite of user's view point.},
author = {Hirokazu, Kato},
journal = {IEIC Technical Report Institute of Electronics Information and Communication Engineers},
number = {652(PRMU2001 222-232)},
pages = {79--86},
title = {{ARToolKit: Library for Vision-based Augmented Reality.}},
volume = {101},
year = {2002}
}
@misc{Hickson2013,
abstract = {This specification defines the 5th major version, first minor revision of the core language of the World Wide Web: the Hypertext Markup Language (HTML). In this version, new features continue to be introduced to help Web application authors, new elements continue to be introduced based on research into prevailing authoring practices, and special attention continues to be given to defining clear conformance criteria for user agents in an effort to improve interoperability.},
author = {Hickson, Ian},
publisher = {W3C},
title = {{HTML 5 Nightly Specification (W3C)}},
url = {http://www.w3.org/html/wg/drafts/html/master/},
year = {2013}
}
@inproceedings{Grosskurth2005,
author = {Grosskurth, Alan and Godfrey, M.W. Michael W},
booktitle = {Software Maintenance, 2005. ICSM'05. Proceedings of the 21st IEEE International Conference on},
doi = {10.1109/ICSM.2005.13},
file = {:Users/eduardolundgren/Google Drive/Faculdade/msc-ufpe-thesis/referencias/Alan.Grosskurth.Web.pdf:pdf},
isbn = {0-7695-2368-4},
keywords = {and has evolved significantly,component reuse,perhaps the most widely,reference architecture,software architecture,software evolution,the web browser is,used soft-,ware application in history,web browser},
organization = {IEEE},
pages = {661--664},
publisher = {IEEE},
title = {{A reference architecture for web browsers}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1510168},
year = {2005}
}
@misc{WC2006,
abstract = {The World Wide Web Consortium (W3C) is an international community where Member organizations, a full-time staff, and the public work together to develop Web standards. Led by Web inventor Tim Berners-Lee and CEO Jeffrey Jaffe, W3C's mission is to lead the Web to its full potential. Contact W3C for more information.},
author = {{W C}},
booktitle = {W3C},
institution = {W3C},
title = {{The World Wide Web Consortium (W3C)}},
url = {http://www.w3.org/},
year = {2006}
}
@misc{Silverlight2013,
abstract = {Silverlight is a powerful development tool for creating engaging, interactive user experiences for Web and mobile applications. Silverlight is a free plug-in, powered by the .NET framework and compatible with multiple browsers, devices and operating systems, bringing a new level of interactivity wherever the Web works.},
author = {Microsoft},
title = {{Silverlight}},
url = {http://www.microsoft.com/silverlight/},
year = {2013}
}
@misc{MediaCapture2013,
abstract = {This document defines a set of JavaScript APIs that allow local media, including audio and video, to be requested from a platform.},
author = {{Daniel C. Burnett}, Voxeo and {Adam Bergkvist}, Ericsson and {Cullen Jennings}, Cisco and Narayanan, Anant},
publisher = {W3C},
title = {{Media Capture and Streams}},
url = {http://www.w3.org/TR/mediacapture-streams/},
year = {2013}
}
@misc{MDN2013,
abstract = {All parts of MDN (docs, demos, and the site itself) are created by an open community of developers.},
author = {Mozilla, Inc.},
title = {{Mozilla Developer Network}},
url = {https://developer.mozilla.org/en-US/},
year = {2013}
}
@article{International2009,
abstract = {This Ecma Standard is based on several originating technologies, the most well known being JavaScript (Netscape) and JScript (Microsoft). The language was invented by Brendan Eich at Netscape and first appeared in that companys Navigator 2.0 browser. It has appeared in all subsequent browsers from Netscape and in all browsers from Microsoft starting with Internet Explorer 3.0. The development of this Standard started in November 1996. The first edition of this Ecma Standard was adopted by the Ecma General Assembly of June 1997. That Ecma Standard was submitted to ISO/IEC JTC 1 for adoption under the fast-track procedure, and approved as international standard ISO/IEC 16262, in April 1998. The Ecma General Assembly of June 1998 approved the second edition of ECMA-262 to keep it fully aligned with ISO/IEC 16262. Changes between the first and the second edition are editorial in nature. The third edition of the Standard introduced powerful regular expressions, better string handling, new control statements, try/catch exception handling, tighter definition of errors, formatting for numeric output and minor changes in anticipation of forthcoming internationalisation facilities and future language growth. The third edition of the ECMAScript standard was adopted by the Ecma General Assembly of December 1999 and published as ISO/IEC 16262:2002 in June 2002. Since publication of the third edition, ECMAScript has achieved massive adoption in conjunction with the World Wide Web where it has become the programming language that is supported by essentially all web browsers. Significant work was done to develop a fourth edition of ECMAScript. Although that work was not completed and not published1 as the fourth edition of ECMAScript, it informs continuing evolution of the language. The present fifth edition of ECMAScript (published as ECMA-262 5th edition) codifies de facto interpretations of the language specification that have become common among browser implementations and adds support for new features that have emerged since the publication of the third edition. Such features include accessor properties, reflective creation and inspection of objects, program control of property attributes, additional array manipulation functions, support for the JSON object encoding format, and a strict mode that provides enhanced error checking and program security. ECMAScript is a vibrant language and the evolution of the language is not complete. Significant technical enhancement will continue with future editions of this specification.},
author = {International, Ecma},
institution = {ECMA},
issn = {09544879},
journal = {JavaScript Specification},
number = {December},
pages = {1--252},
publisher = {ECMA International, http://www.ecma-international.org},
title = {{ECMA-262 ECMAScript Language Specification}},
url = {http://www.ecma-international.org/publications/standards/Ecma-262.htm},
volume = {16},
year = {2009}
}
@misc{AAC2006,
abstract = {Advanced Audio Coding (AAC) is a standardized, lossy compression and encoding scheme for digital audio. Designed to be the successor of the MP3 format, AAC generally achieves better sound quality than MP3 at similar bit rates.},
author = {ISO},
title = {{Information technology -- Generic coding of moving pictures and associated audio information -- Part 7: Advanced Audio Coding (AAC)}},
year = {2006}
}
@article{Krevelen2010,
abstract = {We are on the verge of ubiquitously adopting Augmented Reality (AR) technologies to enhance our percep- tion and help us see, hear, and feel our environments in new and enriched ways. AR will support us in fields such as education, maintenance, design and reconnaissance, to name but a few. This paper describes the field of AR, including a brief definition and development history, the enabling technologies and their characteristics. It surveys the state of the art by reviewing some recent applications of AR technology as well as some known limitations regarding human factors in the use of AR systems that developers will need to overcome.},
author = {Krevelen, D W F Van and Poelman, R},
doi = {10.1155/2011/721827},
file = {:Users/eduardolundgren/Google Drive/Faculdade/msc-ufpe-thesis/referencias/Krevelen.Reality Technologies.Applications.Limitations.pdf:pdf},
issn = {10255834},
journal = {International Journal},
number = {2},
pages = {1--20},
title = {{A Survey of Augmented Reality Technologies , Applications and Limitations}},
url = {http://www.hindawi.com/journals/jia/2011/721827/},
volume = {9},
year = {2010}
}
@misc{Traffic2013,
abstract = {he following overview of page requests per client (\~{}browser) application is based on the user agent information that accompanies most server requests. Please note that agent information does not follow strict guidelines and some programs may provide wrong information on purpose. This report ignores all requests where agent information is missing, or contains any of the following: bot, crawl(er) or spider.},
author = {Wikimedia},
title = {{Wikimedia Traffic Analysis Report - Browsers}},
url = {http://stats.wikimedia.org/archive/squid\_reports/2012-07/SquidReportClients.htm},
year = {2013}
}
@article{Teichrieb2007,
abstract = {This paper surveys the field of Markerless Augmented Reality, specifically online and monocular. This research field is applied by the TechPetro project that aims to define and developed a Markerless Augmented Reality framework for the implementation of Augmented Reality based engineering solutions. In Markerless Augmented Reality, 3D virtual objects are integrated into a 3D real environment in real-time. This is achieved using the world as marker instead of fiducial markers applied in traditional Augmented Reality systems. It discusses major issues related to the field, such as tracking and registration, which become much more complex. This paper also describes the characteristics and experimental results of online monocular Markerless Augmented Reality techniques. Future directions and areas requiring further research are briefly discussed. This survey provides a starting point for anyone interested in researching or using Markerless Augmented Reality.},
author = {Teichrieb, Veronica and Lima, Monte and Lourenc, Eduardo and Bueno, Silva and Kelner, Judith and Santos, Ismael H F},
file = {:Users/eduardolundgren/Google Drive/Faculdade/msc-ufpe-thesis/referencias/VT.Monocular.Markerless.Augmented.Reality.pdf:pdf},
journal = {International Journal of Modeling and Simulation for the Petroleum Industry},
number = {1},
pages = {1--7},
title = {{A Survey of Online Monocular Markerless Augmented Reality}},
url = {http://rpcmod.ganer.ex-br.com/revista/articles/1.pdf},
volume = {1},
year = {2007}
}
@article{RostenFaster2010,
abstract = {The repeatability and efficiency of a corner detector determines how likely it is to be useful in a real-world application. The repeatability is importand because the same scene viewed from different positions should yield features which correspond to the same real-world 3D locations Schmid et al 2000. The efficiency is important because this determines whether the detector combined with further processing can operate at frame rate. Three advances are described in this paper. First, we present a new heuristic for feature detection, and using machine learning we derive a feature detector from this which can fully process live PAL video using less than 5\% of the available processing time. By comparison, most other detectors cannot even operate at frame rate (Harris detector 115\%, SIFT 195\%). Second, we generalize the detector, allowing it to be optimized for repeatability, with little loss of efficiency. Third, we carry out a rigorous comparison of corner detectors based on the above repeatability criterion applied to 3D scenes. We show that despite being principally constructed for speed, on these stringent tests, our heuristic detector significantly outperforms existing feature detectors. Finally, the comparison demonstrates that using machine learning produces significant improvements in repeatability, yielding a detector that is both very fast and very high quality.},
author = {Rosten, Edward and Porter, Reid and Drummond, Tom},
file = {:Users/eduardolundgren/Google Drive/Faculdade/msc-ufpe-thesis/referencias/Rosten.Faster.and.better.PDF:PDF},
institution = {Department of Engineering, Cambridge University, Cambridge, UK. er258@cam.ac.uk},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
number = {1},
pages = {105--119},
publisher = {IEEE},
title = {{Faster and better: a machine learning approach to corner detection}},
url = {http://arxiv.org/abs/0810.2434},
volume = {32},
year = {2010}
}
@misc{TypedArrayPerformance2013,
abstract = {Typed Arrays Performance comparison},
author = {{A Lundgren Melo}, Eduardo},
publisher = {JSPerf},
title = {{Typed Arrays Performance}},
url = {http://jsperf.com/typed-arrays-performance},
year = {2013}
}
@misc{Yan2011,
abstract = {Currently most technologies used by virtual studio systems are extended applications of Virtual Reality (VR) technologies. But for small TV stations and web stations, virtual studio based on traditional VR is so expensive while the FLARToolKit technology used by Augmented Reality (AR) technologies is their top option. However, the calculation speed of FLARToolKit is a little slow and the frame rate is very difficult to reach the live broadcasting video level. My improvements are to apply adaptive thresholds, use sample blurring and change identification frequency, which solves the shortcomings and makes the Virtual Studio faster and better.},
author = {Yan, Yongxin and Zhang, Xiaolei},
booktitle = {2011 International Conference on Mechatronic Science Electric Engineering and Computer MEC},
doi = {10.1109/MEC.2011.6025786},
file = {:Users/eduardolundgren/Google Drive/Faculdade/msc-ufpe-thesis/referencias/Yan.FLARToolKit.pdf:pdf},
institution = {International School, Beijing University of Posts and Telecommunications, Beijing, China},
isbn = {9781612847214},
keywords = {adaptive thresholds,augmented reality (ar),flartoolkit,sample blurring},
pages = {1614--1617},
publisher = {IEEE},
title = {{Research and analysis of the Virtual Reality with FLARToolKit}},
year = {2011}
}
@misc{Theora2011,
abstract = {Theora is a general purpose, lossy video codec.},
author = {{Xiph.Org Foundation}},
title = {{Theora Specification}},
url = {http://theora.org/doc/Theora.pdf},
year = {2011}
}
@article{Kalal2011,
abstract = {This paper investigates long-term tracking of unknown objects in a video stream. The object is defined by its location and extent in a single frame. In every frame that follows, the task is to determine the object's location and extent or indicate that the object is not present. We propose a novel tracking framework (TLD) that explicitly decomposes the long-term tracking task into tracking, learning and detection. The tracker follows the object from frame to frame. The detector localizes all appearances that have been observed so far and corrects the tracker if necessary. The learning estimates detector's errors and updates it to avoid these errors in the future. We study how to identify detector's errors and learn from them. We develop a novel learning method (P-N learning) which estimates the errors by a pair of "experts'': (i) P-expert estimates missed detections, and (ii) N-expert estimates false alarms. The learning process is modeled as a discrete dynamical system and the conditions under which the learning guarantees improvement are found. We describe our real-time implementation of the TLD framework and the P-N learning. We carry out an extensive quantitative evaluation which shows a significant improvement over state-of-the-art approaches.},
author = {Kalal, Zdenek and Mikolajczyk, Krystian and Matas, Jiri},
doi = {10.1109/TPAMI.2011.239},
file = {:Users/eduardolundgren/Google Drive/Faculdade/msc-ufpe-thesis/referencias/Zdenek.Tracking.Learning.Detection.pdf:pdf},
isbn = {2011030153},
issn = {1939-3539},
journal = {IEEE transactions on pattern analysis and machine intelligence},
month = dec,
number = {7},
pages = {1409--1422},
pmid = {22156098},
title = {{Tracking-Learning-Detection.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/22156098},
volume = {34},
year = {2011}
}
@article{Rosten2010,
abstract = {The repeatability and efficiency of a corner detector determines how likely it is to be useful in a real-world application. The repeatability is importand because the same scene viewed from different positions should yield features which correspond to the same real-world 3D locations Schmid et al 2000. The efficiency is important because this determines whether the detector combined with further processing can operate at frame rate. Three advances are described in this paper. First, we present a new heuristic for feature detection, and using machine learning we derive a feature detector from this which can fully process live PAL video using less than 5\% of the available processing time. By comparison, most other detectors cannot even operate at frame rate (Harris detector 115\%, SIFT 195\%). Second, we generalize the detector, allowing it to be optimized for repeatability, with little loss of efficiency. Third, we carry out a rigorous comparison of corner detectors based on the above repeatability criterion applied to 3D scenes. We show that despite being principally constructed for speed, on these stringent tests, our heuristic detector significantly outperforms existing feature detectors. Finally, the comparison demonstrates that using machine learning produces significant improvements in repeatability, yielding a detector that is both very fast and very high quality.},
author = {Rosten, Edward and Porter, Reid and Drummond, Tom},
file = {:Users/eduardolundgren/Library/Application Support/Mendeley Desktop/Downloaded/Rosten, Drummond - Unknown - Machine learning for high-speed corner detection.pdf:pdf},
institution = {Department of Engineering, Cambridge University, Cambridge, UK. er258@cam.ac.uk},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
number = {1},
pages = {1--14},
publisher = {IEEE},
title = {{Machine learning for high-speed corner detection}},
url = {http://arxiv.org/abs/0810.2434},
volume = {32},
year = {2010}
}
@phdthesis{Homography2009,
abstract = {This essay has been written to provide the reader with a treatment of homography estimation and its use in today's computer vision applications. The topic is motivated by a discussion of various situations where homography estimation is required and an overview of other geometric transformations so as to situate homographies in the correct context. Various algorithms are discussed ranging from the most basic linear algorithm to statistical optimization. Non-linear algorithms for homography estimation are broken down into the cost functions that they aim to minimize. Robust estimation techniques with respect to outlier correspondences are covered as well as al gorithms making use of non-point correspondences such as lines and conics. Finally, a survey of publicly available software in this area is provided.},
author = {Dubrofsky, Elan},
booktitle = {The University of Britsh Columbia},
file = {:Users/eduardolundgren/Google Drive/Faculdade/msc-ufpe-thesis/referencias/Dubrofsky.Elan.Homography.Estimation.pdf:pdf},
number = {March},
school = {The University of Britsh Columbia},
title = {{Homography Estimation}},
type = {Essay},
year = {2009}
}
@article{Calonder2010,
abstract = {We propose to use binary strings as an efficient feature point descriptor, which we call BRIEF.We show that it is highly discriminative even when using relatively few bits and can be computed using simple intensity difference tests. Furthermore, the descriptor similarity can be evaluated using the Hamming distance, which is very efficient to compute, instead of the L 2 norm as is usually done. As a result, BRIEF is very fast both to build and to match. We compare it against SURF and U-SURF on standard benchmarks and show that it yields a similar or better recognition performance, while running in a fraction of the time required by either.},
author = {Calonder, Michael and Lepetit, Vincent and Strecha, Christoph and Fua, Pascal},
chapter = {56},
doi = {10.1007/978-3-642-15561-1\_56},
editor = {Daniilidis, Kostas and Maragos, Petros and Paragios, Nikos},
file = {:Users/eduardolundgren/Google Drive/Faculdade/msc-ufpe-thesis/referencias/Lepetit.BRIEF.pdf:pdf},
isbn = {9783642155604},
issn = {07364679},
journal = {Computer},
number = {3},
pages = {778--792},
pmid = {19500939},
publisher = {Springer},
series = {Lecture Notes in Computer Science},
title = {{BRIEF : Binary Robust Independent Elementary Features}},
url = {http://www.springerlink.com/index/H8H1824827036042.pdf},
volume = {6314},
year = {2010}
}
@misc{WebGL2013,
abstract = {This specification describes an additional rendering context and support objects for the HTML 5 canvas element [CANVAS]. This context allows rendering using an API that conforms closely to the OpenGL ES 2.0 API.},
author = {Inc., Apple},
publisher = {Khronos},
title = {{WebGL Specification}},
url = {http://www.khronos.org/registry/webgl/specs/latest/},
year = {2013}
}
@misc{Gecko2013,
abstract = {Gecko is the name of the layout engine developed by the Mozilla Project. It was originally named NGLayout. Gecko's function is to read web content, such as HTML, CSS, XUL, JavaScript, and render it on user's screen or print it. In XUL-based applications Gecko is used to render the application's user interface as well.},
author = {Mozilla, Inc.},
title = {{Gecko}},
url = {https://developer.mozilla.org/en-US/docs/Mozilla/Gecko},
year = {2013}
}
@article{Lepetit2005,
abstract = {Many applications require tracking of complex 3D objects. These include visual servoing of robotic arms on specific target objects, Augmented Reality systems that require real-time registration of the object to be augmented, and head tracking systems that sophisticated interfaces can use. Computer Vision offers solutions that are cheap, practical and non-invasive. This survey reviews the different techniques and approaches that have been developed by industry and research. First, important mathematical tools are introduced: Camera representation, robust estimation and uncertainty estimation. Then a comprehensive study is given of the numerous approaches developed by the Augmented Reality and Robotics communities, beginning with those that are based on point or planar fiducial marks and moving on to those that avoid the need to engineer the environment by relying on natural features such as edges, texture or interest. Recent advances that avoid manual initialization and failures due to fast motion are also presented. The survery concludes with the different possible choices that should be made when implementing a 3D tracking system and a discussion of the future of vision-based 3D tracking. Because it encompasses many computer vision techniques from lowlevel vision to 3D geometry and includes a comprehensive study of the massive literature on the subject, this survey should be the handbook of the student, the researcher, or the engineer who wants to implement a 3D tracking system.},
author = {Lepetit, Vincent and Fua, Pascal},
doi = {10.1561/0600000001},
file = {:Users/eduardolundgren/Google Drive/Faculdade/msc-ufpe-thesis/referencias/Lepetit.Monocular.Model.Based.3D.Tracking.pdf:pdf},
isbn = {1933019034},
issn = {15722740},
journal = {Foundations and Trends® in Computer Graphics and Vision},
number = {1},
pages = {1--89},
publisher = {Now Publishers Inc},
series = {Foundation. Trends Comput. Graph. Vis. (USA)},
title = {{Monocular Model-Based 3D Tracking of Rigid Objects}},
url = {http://www.nowpublishers.com/product.aspx?product=CGV\&doi=0600000001},
volume = {1},
year = {2005}
}
@misc{Firefox2013,
author = {Mozilla, Inc.},
title = {{Mozilla Firefox Browser}},
url = {http://www.mozilla.org/en-US/firefox/new/},
year = {2013}
}
@inproceedings{Viola2001,
author = {Viola, P. and Jones, M.},
booktitle = {Proceedings of the 2001 IEEE Computer Society Conference on Computer Vision and Pattern Recognition. CVPR 2001},
doi = {10.1109/CVPR.2001.990517},
file = {:Users/eduardolundgren/Google Drive/Faculdade/msc-ufpe-thesis/referencias/Viola.Jones.pdf:pdf},
isbn = {0-7695-1272-0},
pages = {I--511--I--518},
publisher = {IEEE Comput. Soc},
title = {{Rapid object detection using a boosted cascade of simple features}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=990517},
volume = {1},
year = {2001}
}
@misc{Chrome2010,
abstract = {Google Chrome is a freeware web browser developed by Google that uses the WebKit layout engine. It was first released as a beta version for Microsoft Windows on September 2, 2008, and the public stable release was on December 11, 2008. As of January 2012update, Google Chrome has approximately 2528\% worldwide usage share of web browsers, making it the second or the third most widely used browser, according to different estimates.1234 Google web browsers, Chrome + Android web browser, are now used more on wikimedia than any other browser.5},
author = {Inc., Google},
booktitle = {Group},
pages = {1--5},
publisher = {Google, Inc.},
title = {{Google Chrome Browser}},
url = {https://www.google.com/chrome},
year = {2010}
}
@misc{WebRTC2013,
abstract = {WebRTC is a free, open project that enables web browsers with Real-Time Communications (RTC) capabilities via simple Javascript APIs. The WebRTC components have been optimized to best serve this purpose.},
author = {Inc., Google and Inc., Mozilla and Inc., Opera},
title = {{WebRTC}},
url = {http://www.webrtc.org/},
year = {2013}
}
@article{Pablo2013,
author = {Paulo, Jo\~{a}o and Lima, S M and Pinheiro, Pablo C and Teichrieb, Veronica and Kelner, Judith},
file = {:Users/eduardolundgren/Google Drive/Faculdade/msc-ufpe-thesis/referencias/Pablo.SVR.AR.web.pdf:pdf},
title = {{Markerless Tracking Solutions for Augmented Reality on the Web}}
}
@misc{Canvas2013,
abstract = {The canvas element provides scripts with a resolution-dependent bitmap canvas, which can be used for rendering graphs, game graphics, art, or other visual images on the fly.},
author = {Community, WHATWG},
publisher = {WHATWG Community},
title = {{The canvas element}},
url = {http://www.whatwg.org/specs/web-apps/current-work/multipage/the-canvas-element.html},
year = {2013}
}
@misc{Vorbis2012,
author = {Foundation, Xiph.Org},
title = {{Vorbis specification}},
url = {http://xiph.org/vorbis/doc/Vorbis\_I\_spec.html},
year = {2012}
}
@book{Hartley2004,
abstract = {A basic problem in computer vision is to understand the structure of a real world scene. This book covers relevant geometric principles and how to represent objects algebraically so they can be computed and applied. Recent major developments in the theory and practice of scene reconstruction are described in detail in a unified framework. Richard Hartley and Andrew Zisserman provide comprehensive background material and explain how to apply the methods and implement the algorithms.},
author = {Hartley, Richard and Zisserman, Andrew},
booktitle = {Cambridge University Press},
chapter = {189},
isbn = {0521540518},
issn = {05215405},
number = {2},
pages = {672},
publisher = {Cambridge University Press},
title = {{Multiple View Geometry in Computer Vision}},
url = {http://www.robots.ox.ac.uk/~vgg/hzbook/},
volume = {2},
year = {2004}
}
